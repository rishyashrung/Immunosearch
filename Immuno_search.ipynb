{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import papermill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_file_path = \"/Users/rishyashrung/Downloads/Docs/im folder/1130_MHCI_1/1130_MHCI_1.xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = []\n",
    "file_name = '1130_MHCI_1'\n",
    "output_file_path = \"/Users/rishyashrung/Proteomics/Immunosearch/test/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "work_dir = \"/Users/rishyashrung/Proteomics/Immunosearch/test/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions \n",
    "\n",
    "#fn for creating files from a list and file_name\n",
    "def create_files(pep, file_name):\n",
    "\n",
    "    ofile = open(file_name + \".fasta\", \"w\")\n",
    "\n",
    "    for i in range(len(pep)):\n",
    "        ofile.write('>' + '\\n' + pep[i] + '\\n')\n",
    "    ofile.close()\n",
    "\n",
    "    # peptide list for parsing\n",
    "    ofile = open(file_name + '_2.fasta', \"w\")\n",
    "\n",
    "    for i in range(len(pep)):\n",
    "        ofile.write(pep[i] + '\\n')\n",
    "    ofile.close()\n",
    "    \n",
    "    return print(\"\\t\" + \"files\", file_name, \",\", file_name + '_2', \"created\" )\n",
    "\n",
    "#fn for parsing and categorizing blast output\n",
    "def parse_categorize(database_fasta, blast_out, fasta2): #requires inputs with file extension\n",
    "\n",
    "    input1= SeqIO.parse(database_fasta,\"fasta\") # blastp reference database\n",
    "    seqdb={}\n",
    "    for record in input1:\n",
    "        seq=str(record.seq)\n",
    "        if record.id not in seqdb:\n",
    "            seqdb[record.id]=seq\n",
    "\n",
    "    input2= open(blast_out,\"r\") # blastp output\n",
    "    input3= open(fasta2,\"r\") # novel peptide tab txt\n",
    "    output= open('categorized_' + blast_out,\"w\")\n",
    "\n",
    "\n",
    "    blastout={}\n",
    "    hits_dic={}\n",
    "    for line in input2:\n",
    "        row=line.strip().split(\"\\t\")\n",
    "        qid=row[-2]\n",
    "        sid=row[1]\n",
    "        sseq=seqdb[sid]\n",
    "        ident=row[2]\n",
    "        peplen=int(row[3])\n",
    "        mismatch=row[4]\n",
    "        alignlen=int(row[6])-int(row[5])+1\n",
    "        sstart=int(row[7])\n",
    "        send=int(row[8])\n",
    "        gap=row[11]\n",
    "        evalue=float(row[-5])\n",
    "        alignseq=row[-1]\n",
    "        category=\"NA\"\n",
    "        single_sub_pos=\"NA\"\n",
    "        if sstart>3:\n",
    "            Nterm_seq=sseq[sstart-4:sstart+2] #check up 3 amino acid before N-term of this peptide\n",
    "        else:\n",
    "            Nterm_seq=sseq[:sstart]\n",
    "\n",
    "        if len(sseq)-send<3:\n",
    "            Cterm_seq=sseq[send-1:]\n",
    "        else:\n",
    "            Cterm_seq=sseq[send-3:send+3]\n",
    "\n",
    "        if alignlen==peplen:\n",
    "            if float(ident)==100:\n",
    "                category=\"match to known protein\"\n",
    "            \n",
    "            elif int(gap)==0 and int(mismatch)==1:\n",
    "                category=\"map to known protein with 1 aa mismatch\"\n",
    "                for i in range(peplen):\n",
    "                    if qid[i]!=alignseq[i]:\n",
    "                        single_sub_pos=str(i+1)\n",
    "\n",
    "            elif int(gap)==1 and int(mismatch)==0:\n",
    "                category=\"map to known protein with 1 aa insertion\"\n",
    "            else:\n",
    "                category=\"novelpep (map to known protein with more than 2 mismatched aa)\"\n",
    "        elif peplen-alignlen==1 and float(ident)==100:\n",
    "            category=\"map to known protein with 1 aa deletion\"\n",
    "\n",
    "        else:\n",
    "            category=\"novelpep (map to known protein with more than 2 mismatched aa)\"\n",
    "        \n",
    "        if qid not in hits_dic:\n",
    "            hits_dic[qid]=evalue\n",
    "            blastout[qid]=[category,sid,ident,peplen,single_sub_pos,Nterm_seq,alignseq,Cterm_seq,alignlen,mismatch,gap]\n",
    "        else:\n",
    "            if evalue<hits_dic[qid]:\n",
    "                hits_dic[qid]=evalue\n",
    "                blastout[qid]=[category,sid,ident,peplen,single_sub_pos,Nterm_seq,alignseq,Cterm_seq,alignlen,mismatch,gap]\n",
    "\n",
    "    #header=input3.readline().strip().split(\"\\t\")\n",
    "\n",
    "    header=[\"Query\",\"blastp_category\",\"blastp_match\",\"identity\",\"peplen\",\"sub_pos\",\"Nterm-seq(3aa)\",\"aligned_seq\",\"Cterm-seq(3aa)\",\"alignlen\",\"mismatch\",\"gap\"]\n",
    "    output.write(\"\\t\".join(header)+\"\\n\")\n",
    "\n",
    "    for line in input3:\n",
    "        row=line.strip().split(\"\\t\")\n",
    "        peptide=row[0]\n",
    "        if peptide in blastout:\n",
    "            results=blastout[row[0]]\n",
    "            newrow=row+results\n",
    "            output.write(\"\\t\".join(map(str,newrow))+\"\\n\")\n",
    "        else:\n",
    "            newrow=row+[\"novelpep (no match to known protein found)\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\"]\n",
    "            output.write(\"\\t\".join(map(str,newrow))+\"\\n\")\n",
    "\n",
    "\n",
    "    input2.close()\n",
    "    input3.close()\n",
    "    output.close()\n",
    "   \n",
    "    #adding headers to the novel blast output\n",
    "    header_names = [\"qseqid\", \"sseqid\", \"pident\", \"qlen\", \"mismatch\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\", \"gaps\", \"qseq\", \"sseq\"]\n",
    "    novel_file = pd.read_table('categorized_' + blast_out, sep ='\\t', names = header_names)\n",
    "    header_names = [\"qseqid\", \"sseqid\", \"pident\", \"qlen\", \"mismatch\", \"qstart\", \"qend\", \"sstart\", \"send\", \"evalue\", \"bitscore\", \"gaps\", \"qseq\", \"sseq\"]\n",
    "    blast_file = pd.read_table(blast_out, sep ='\\t', names = header_names)\n",
    "    blast_file\n",
    "    #to check if any keys are missing in the dictionary seqdb[]\n",
    "    missing = blast_file[~blast_file[\"sseqid\"].isin(seqdb.keys())]\n",
    "    if (len(missing) == 0):\n",
    "        return print(\"\\t\"+ 'all is gud for',blast_out)\n",
    "    else:\n",
    "        return print('dictionary error') #make sure the dictionary key is the same as the accession in\n",
    "    \n",
    "\n",
    "def get_pos(substring, string):\n",
    "# Find the starting position\n",
    "    start_position = string.find(substring)\n",
    "\n",
    "    if start_position != -1:\n",
    "        # Calculate the ending position\n",
    "        end_position = start_position + len(substring) - 1\n",
    "        return(start_position, end_position)\n",
    "\n",
    "\n",
    "#fn that gets matches and position of matches from peptide_list to fasta\n",
    "def find_matches(peptide, db, query):\n",
    "    search_6ft = {}\n",
    "    pos_6ft = {}\n",
    "    for string in peptide:\n",
    "        search_6ft[string] = []\n",
    "        for key, value in db.items():\n",
    "            if string in value:\n",
    "                if (query == '6FT'):\n",
    "                    combi = (key, get_pos(string,value))\n",
    "                    search_6ft[string].append(combi)\n",
    "                elif (query == 'PCPS'):\n",
    "                    search_6ft[string].append(key)\n",
    "                else:\n",
    "                    return print(\"specify find matches query: 6FT or PCPS\")\n",
    "    unmatched = []\n",
    "    #fn for filtering the 6FT matched dictionary\n",
    "    def my_filtering_function(pair):\n",
    "        key, value = pair\n",
    "        if value == []:\n",
    "            return False  # filter pair out of the dictionary\n",
    "        else:\n",
    "            return True  # keep pair in the filtered dictionary\n",
    "        \n",
    "    matched = dict(filter(my_filtering_function, search_6ft.items()))\n",
    "    positions = dict(filter(my_filtering_function, pos_6ft.items()))\n",
    "\n",
    "    for key, value in search_6ft.items():\n",
    "        if (value == []):\n",
    "            unmatched.append(key)\n",
    "    if (len(matched) + len(unmatched) == len(search_6ft)):  #to make sure the dictionary filter works fine\n",
    "        return (matched, unmatched)\n",
    "    else:\n",
    "        return print(\"\\t\" + \"error in separating matches\")\n",
    "    \n",
    "def split_string(s):\n",
    "    splits_dict = {}\n",
    "    # Ensure the string is long enough to be split into two parts each with at least `min_length` characters\n",
    "    if len(s) < 6:\n",
    "        return splits_dict\n",
    "    \n",
    "    for i in range(3, len(s) - 2):\n",
    "        part1 = s[:i]\n",
    "        part2 = s[i:]\n",
    "        if len(part2) >= 3:\n",
    "            splits_dict[part1] = part2\n",
    "    return splits_dict\n",
    "\n",
    "def PCPS(input_file):\n",
    "        \n",
    "    input1= SeqIO.parse('db/human_canonical.fasta',\"fasta\") \n",
    "    seqdb={}\n",
    "    for record in input1:\n",
    "            seq=str(record.seq)\n",
    "            if record.id not in seqdb:\n",
    "                    seqdb[record.id]=seq\n",
    "    \n",
    "    input = open(input_file, \"r\")\n",
    "    output = open('cis_PCPS', \"w\")\n",
    "    output_2 = open('trans_PCPS', \"w\")\n",
    "    for line in input:\n",
    "            row=line.strip().split(\"\\t\")\n",
    "            pep = row[0]\n",
    "            split_combinations = split_string(pep)\n",
    "            part1_list = list(split_combinations.keys())\n",
    "            part2_list = list(split_combinations.values())\n",
    "            match_1, unmatch_1 = find_matches(part1_list, seqdb, 'PCPS')\n",
    "            match_2, unmatch_2 = find_matches(part2_list, seqdb, 'PCPS')\n",
    "            row = []\n",
    "            for key,value in match_1.items():\n",
    "                    for pro_1 in match_1[key]:\n",
    "                            if (split_combinations[key] in match_2.keys()):\n",
    "                                    for pro_2 in match_2[split_combinations[key]]:\n",
    "                                            if pro_1 == pro_2:\n",
    "                                                result = (f\"{key}|{split_combinations[key]}\" + \"\\t\" + f\"{pro_2}\")\n",
    "                                                output.write(str(pep) + \"\\t\" + result + \"\\n\")\n",
    "                                            else:\n",
    "                                                result_2 = (f\"{key}|{split_combinations[key]}\" + \"\\t\" + f\"{pro_1}:{pro_2}\")\n",
    "                                                output_2.write(str(pep) + \"\\t\" + result_2 + \"\\n\")\n",
    "    input.close()\n",
    "    output.close()\n",
    "    output_2.close()\n",
    "    return print(\"\\t\" + \"separate files cis_PCPS and trans_PCPS created for spliced peptides\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 08/02/2024 22:16:16\n",
      "New DB name:   /Users/rishyashrung/Proteomics/Immunosearch/db/APD_Hs_all\n",
      "New DB title:  db/APD_Hs_all.fasta\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 877168 sequences in 14.8206 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 08/02/2024 22:16:32\n",
      "New DB name:   /Users/rishyashrung/Proteomics/Immunosearch/db/human_canonical\n",
      "New DB title:  db/human_canonical.fasta\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Adding sequences from FASTA; added 82518 sequences in 2.11661 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 08/02/2024 22:16:36\n",
      "New DB name:   /Users/rishyashrung/Proteomics/Immunosearch/db/sap_db\n",
      "New DB title:  db/sap_db.fa\n",
      "Sequence type: Protein\n",
      "Keep MBits: T\n",
      "Maximum file size: 3000000000B\n",
      "Ignoring sequence 'lcl|HPMD_1002557' as it has no sequence data\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 563332: 327, 334-337, 339, 343-347, 349-352, 354, 358-362, 364-367, 369, 373-377, 379-382, 384, 388-392, 394-398, 400, 404-408, 410-414, 416, 420-424, 426-430, 432, 436-440, 442-446, 448, 452-456, 458-462, 464, 466, 1163, 1170-1172, 1174, 1178-1181, 1183-1186, 1188, 1190\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 571130: 301, 307-310, 312, 316-320, 322-325, 327, 331-335, 337-341, 343, 347-351, 353-357, 359, 363-367, 369-372, 374, 378-382, 384-387, 389, 391\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 586836: 492, 509, 515-518, 520, 524-528, 530-533, 535, 539-543, 545-548, 550, 554-558, 560-563, 565, 569-573, 575-578, 580, 584-588, 590-593, 595, 599-603, 605-609, 611, 615-619, 621-625, 627, 631-635, 637-641, 643, 647-651, 653-657, 659, 663-667, 669-673, 675, 679-683, 685-689, 691, 693\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 1206620: 2850, 2857-2860, 2862, 2866-2870, 2872-2874, 2876, 2880-2884, 2886-2890, 2892, 2896-2900, 2902-2906, 2908, 2912-2916, 2918-2922, 2924, 2928-2932, 2934-2938, 2940, 2944-2948, 2950-2954, 2956, 2960-2964, 2966-2970, 2972, 2976-2980, 2982-2986, 2988, 2990\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 1385332: 770, 777-780, 782, 786-790, 792-795, 797, 801-805, 807-811, 813, 815\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 1516522: 814, 820-823, 825, 829-833, 835-838, 840, 844-848, 850-854, 856, 860-864, 866-870, 872, 876-880, 882-886, 888, 892-896, 898-902, 904, 908-912, 914-918, 920, 924-928, 930-934, 936, 940-944, 946-950, 952, 954\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 1703878: 557, 564-567, 569, 573-577, 579-582, 584, 588-592, 594-598, 600, 604-608, 610-614, 616, 620-624, 626-630, 632, 636-640, 642-646, 648, 652-656, 658-662, 664, 668-672, 674-678, 680, 682, 1045, 1052-1055, 1057, 1061-1065, 1067-1070, 1072, 1076-1080, 1082-1086, 1088, 1092-1096, 1098-1102, 1104, 1108-1112, 1114-1118, 1120, 1124-1128, 1130-1134, 1136, 1140-1144, 1146-1150, 1152, 1154\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 1885484: 238-239\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 2427780: 854-855\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 4411704: 49-50\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5003844: 192, 202, 211, 217-220, 222, 225-229, 231-234, 236, 238\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5243092: 305, 312-315, 317, 321-325, 327-330, 332, 336-340, 342-345, 347, 349\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5275550: 454, 460-463, 465, 469-473, 475-477, 479, 483-487, 489-492, 494, 498-502, 504-507, 509, 513-517, 519-523, 525, 529-533, 535-539, 541, 545-549, 551-555, 557, 561-565, 567-571, 573, 575\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5556836: 197\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5653552: 51-52\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5653554: 51-52\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5653556: 51-52\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5654782: 51-52\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5654784: 51-52\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5654786: 50-51\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 5991918: 220, 237, 243-246, 248, 252-256, 258-261, 263, 267-271, 273-276, 278, 282-286, 288-291, 293, 297-301, 303-306, 308, 312-316, 318-321, 323, 327-331, 333-336, 338, 342-346, 348-352, 354, 358-362, 364-368, 370, 374-378, 380-384, 386, 390-394, 396-400, 402, 406-410, 412-416, 418, 422-426, 428-432, 434, 438-442, 444-448, 450, 454-458, 460-464, 466, 470-474, 476-480, 482, 486-490, 492-496, 498, 502-507, 509-513, 515, 519-524, 526-530, 532, 536-541, 543-547, 549, 553-558, 560-564, 566, 570-575, 577-581, 583, 587-592, 594-598, 600, 604-609, 611-615, 617, 621-626, 628-632, 634, 638-643, 645-649, 651, 655-660, 662-666, 668, 672-677, 679-683, 685, 689-694, 696-700, 702, 706-711, 713-717, 719, 723-728, 730-734, 736, 738, 2412, 2429, 2435-2438, 2440, 2444-2448, 2450-2453, 2455, 2459-2463, 2465-2468, 2470, 2474-2478, 2480-2483, 2485, 2489-2493, 2495-2498, 2500, 2504-2508, 2510-2513, 2515, 2519-2523, 2525-2528, 2530, 2532\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 6518502: 664-665\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 7106652: 339, 346-349, 351, 355-359, 361-365, 367, 371-375, 377-381, 383, 387-391, 393-397, 399, 401\n",
      "FASTA-Reader: Ignoring invalid residues at position(s): On line 7516406: 399, 406-409, 411, 415-419, 421-424, 426, 430-434, 436-439, 441, 445-449, 451-455, 457, 461-465, 467-471, 473, 477-481, 483-487, 489, 493-497, 499-503, 505, 509-513, 515-519, 521, 525-529, 531-535, 537, 541-545, 547-551, 553, 557-561, 563-567, 569, 573-577, 579-583, 585, 587, 1476, 1483-1486, 1488, 1492-1496, 1498-1501, 1503, 1507-1511, 1513-1516, 1518, 1522-1526, 1528-1532, 1534, 1538-1542, 1544-1548, 1550, 1552\n",
      "Adding sequences from FASTA; added 4691537 sequences in 141.162 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#make databse from known HLA peptides fasta file\n",
    "#!makeblastdb -in db/APD_Hs_all.fasta -dbtype prot -out db/APD_Hs_all\n",
    "\n",
    "#make human canonical protein blast database from fasta\n",
    "#!makeblastdb -in db/human_canonical.fasta  -dbtype prot -parse_seqids -out db/human_canonical\n",
    "\n",
    "#make SAAV blast database from fasta\n",
    "#!makeblastdb -in db/sap_db.fa  -dbtype prot -parse_seqids -out db/sap_db\n",
    "\n",
    "#Make sixframe translated database from ref genome\n",
    "#!seqkit translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def immuno_search(work_dir, input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name):   #path of files of peptides and gibbs classification, MHC_class as an integer, Gibbs clusters to select as an array, output_file_path with / at the end\n",
    "    os.chdir(work_dir)\n",
    "    print(\"loading into work directory at\", work_dir)\n",
    "    # peptide length 8-11, removing gibbs junk and DB matched\n",
    "    all_data = pd.ExcelFile(input_file_path)\n",
    "    data = pd.read_excel(all_data, file_name)\n",
    "    gibbs = pd.read_excel(all_data, 'gibbs_clustering')\n",
    "    #data = pd.read_csv(path_peptides) #PSM table from PEAKS\n",
    "    #gibbs = pd.read_csv(path_gibbs) #Gibbs clustering CSV\n",
    "    print(\"filtering peptides found by DB search\")\n",
    "    data = data[data[\"Found By\"] != 'DB Search']\n",
    "    if (len(gibbs_cluster) != 0):\n",
    "        print(\"Selected gibbs clusters based on input\")\n",
    "        gibbs = gibbs[gibbs[\"Gn\"].isin(gibbs_cluster)]\n",
    "    else:\n",
    "        print(\"selecting all gibbs clusters\")\n",
    "        gibbs = gibbs\n",
    "    \n",
    "    if (MHC_class == '1'):\n",
    "        print(\"selecting peptides with length between 8 and 11 AA\")\n",
    "        gibbs = gibbs[gibbs[\"Sequence\"].str.len().between(8,11)]\n",
    "    elif (MHC_class == '2'):\n",
    "        print(\"selecting peptides with length between 12 and 17 AA\")\n",
    "        gibbs = gibbs[gibbs[\"Sequence\"].str.len().between(12,17)]\n",
    "    elif (MHC_class == \"E\"):\n",
    "        print(\"selecting peptides with length between 8 and 15 AA\")\n",
    "        gibbs = gibbs[gibbs[\"Sequence\"].str.len().between(8,15)]\n",
    "    else:\n",
    "        print(\"!!! not filtered by length\")\n",
    "\n",
    "    data = data[data[\"Peptide\"].isin(gibbs[\"Sequence\"])]\n",
    "    list = pd.unique(data[\"Peptide\"])\n",
    "    pep = list.tolist()\n",
    "    blast_p = pep\n",
    "    print(\"generating lists and files for further analysis\")\n",
    "    create_files(pep,'peptides')\n",
    "\n",
    "\n",
    "    #blast against known HLA peptides\n",
    "    if(len(pep) != 0):\n",
    "\n",
    "        if(len(pep) == 1): #coz I'm a grammar Nazi :)\n",
    "            print(str(len(pep)) + \" peptide being searched for known HLAs\")\n",
    "        else:\n",
    "            print( str(len(pep)) + \" peptides being searched for known HLAs\")\n",
    "        \n",
    "        !blastp -task blastp-short -query peptides.fasta -db db/APD_Hs_all -out HLA_blast_out -evalue 10.0 -outfmt \"6 qseqid saccver pident qlen mismatch qstart qend sstart send evalue bitscore gaps qseq sseq\"\n",
    "\n",
    "        #parsing and catergorizing HLA_blast output\n",
    "        print(\"\\t\"+ \"reading output\")\n",
    "        parse_categorize('db/APD_Hs_all.fasta', 'HLA_blast_out', 'peptides_2.fasta')\n",
    "\n",
    "        #known HLA\n",
    "        print(\"\\t\"+ \"generating lists and files for further analysis\")\n",
    "        output_HLA = pd.read_table('categorized_HLA_blast_out')\n",
    "        known = output_HLA[output_HLA[\"blastp_category\"] == 'match to known protein']\n",
    "        list = known[\"Query\"] \n",
    "        pep = list.to_list()\n",
    "\n",
    "        if (len(pep) != 0):\n",
    "            print(\"\\t\"+ \"known HLA found\")\n",
    "            ofile = open(\"known_HLA.fasta\", \"w\")\n",
    "\n",
    "            for i in range(len(pep)):\n",
    "                ofile.write('>' + '\\n' + pep[i] + '\\n')\n",
    "            ofile.close()\n",
    "        else:\n",
    "            print(\"\\t\"+ \"no known HLA found\")\n",
    "\n",
    "        known = output_HLA[output_HLA[\"blastp_category\"] != 'match to known protein']\n",
    "        list = known[\"Query\"] \n",
    "        pep = list.to_list()\n",
    "    else:\n",
    "        print(\"No peptides to search for known HLAs\")\n",
    "\n",
    "    \n",
    "    if (len(pep) != 0): #to prevent blast with empty query\n",
    "        \n",
    "        create_files(pep, 'to_blastp')\n",
    "\n",
    "        if (len(pep) == 1):\n",
    "            print(str(len(pep)) + \" peptide being searched for human canonical proteins\")\n",
    "        else:\n",
    "            print(str(len(pep)) + \" peptides being searched for human canonical proteins\")\n",
    "        \n",
    "        #blast all proteins against human canonical proteins\n",
    "        !blastp -task blastp-short -query to_blastp.fasta -db db/human_canonical -out blastp_out_human_canonical -evalue 10.0 -outfmt \"6 qseqid sseqid pident qlen mismatch qstart qend sstart send evalue bitscore gaps qseq sseq\"\n",
    "        print(\"\\t\"+ \"reading output\")\n",
    "        parse_categorize('db/human_canonical.fasta', 'blastp_out_human_canonical', 'to_blastp_2.fasta')\n",
    "        output  = pd.read_table('categorized_blastp_out_human_canonical')\n",
    "        \n",
    "        #preparing fasta files of proteins to search 6FT database\n",
    "        to_6ft = output[(output[\"blastp_category\"] != 'map to known protein with 1 aa mismatch') & (output[\"blastp_category\"] != 'match to known protein')]\n",
    "        list = to_6ft[\"Query\"] \n",
    "        pep = list.to_list()\n",
    "\n",
    "        create_files(pep, 'to_6ft')\n",
    "       \n",
    "        #preparing fasta files of proteins with 1 AA mismatch\n",
    "        mismatched = output[output[\"blastp_category\"] == 'map to known protein with 1 aa mismatch']\n",
    "        list = mismatched[\"Query\"] \n",
    "        pep = list.to_list()\n",
    "        SAAV = pep\n",
    "    else:\n",
    "        print(\"blastp input empty\")\n",
    "\n",
    "    print(\"\\t\"+ \"generating lists and files for further analysis\")\n",
    "    \n",
    "    \n",
    "    if (len(pep) != 0): #to prevent blast with empty query\n",
    "\n",
    "        create_files(pep,'SAAV')\n",
    "        \n",
    "        if (len(pep) == 1):  #more grammar Nazi\n",
    "            print(str(len(pep)) + \" peptide being searched for Single Amino Acid Variants\")\n",
    "        else:\n",
    "            print(str(len(pep)) + \" peptides being searched for Single Amino Acid Variants\")\n",
    "            \n",
    "        #blastp against db_SAP (single amino acids polymorphisms)\n",
    "        !blastp -task blastp-short -query SAAV.fasta -db db/sap_db -out blast_out_SAAV -evalue 10.0 -outfmt \"6 qseqid saccver pident qlen mismatch qstart qend sstart send evalue bitscore gaps qseq sseq\"\n",
    "        \n",
    "        print(\"\\t\"+ \"reading output\")\n",
    "        parse_categorize('db/sap_db.fa', 'blast_out_SAAV', 'SAAV_2.fasta')\n",
    "\n",
    "\n",
    "        output = pd.read_table(\"categorized_blast_out_SAAV\")\n",
    "        not_SNP = output[output[\"blastp_category\"] != 'match to known protein']\n",
    "        pep = not_SNP[\"Query\"]\n",
    "        pep = pep.to_list()\n",
    "\n",
    "        ofile = open(\"not_SAAV.fasta\", \"w\")\n",
    "\n",
    "        for i in range(len(pep)):\n",
    "            ofile.write('>' + '\\n' + pep[i] + '\\n')\n",
    "        ofile.close()\n",
    "\n",
    "    else:\n",
    "        print(\"no potential SAAVs, proceeding to 6FT search\")\n",
    "\n",
    "    #searches peptides in 6FT db\n",
    "    \n",
    "    pep = to_6ft[\"Query\"]\n",
    "\n",
    "    if(len(pep) != 0):\n",
    "\n",
    "        if(len(pep) == 1):\n",
    "            \n",
    "            print(str(len(pep)) + \" peptide being searched in the six frame translated human genome\")\n",
    "            \n",
    "            !seqkit grep --by-seq --ignore-case --threads 12 --seq-type protein --pattern-file to_6ft_2.fasta db/human_6FT_m.fasta > 6ft_out\n",
    "            \n",
    "            input1= SeqIO.parse('6ft_out',\"fasta\") # 6FT results to dict\n",
    "            seqdb={}\n",
    "            for record in input1:\n",
    "                seq=str(record.seq)\n",
    "                if record.description not in seqdb:\n",
    "                    seqdb[record.description]=seq\n",
    "            \n",
    "            if (len(seqdb) == 0):\n",
    "                print(\"no match to 6FT\")\n",
    "                unmatched = pep\n",
    "                matched = []\n",
    "            else:\n",
    "                matched = pep\n",
    "                unmatched = []\n",
    "\n",
    "        else:\n",
    "            print(str(len(pep)) + \" peptides being searched in the six frame translated human genome\")\n",
    "\n",
    "            !seqkit grep --by-seq --ignore-case --threads 12 --seq-type protein --pattern-file to_6ft_2.fasta db/human_6FT_m.fasta > 6ft_out\n",
    "\n",
    "            print(\"\\t\"+ \"writing 6FT results to dictionary\")\n",
    "\n",
    "            input1= SeqIO.parse('6ft_out',\"fasta\") # 6FT results to dict\n",
    "            seqdb={}\n",
    "            for record in input1:\n",
    "                seq=str(record.seq)\n",
    "                if record.description not in seqdb:\n",
    "                    seqdb[record.description]=seq\n",
    "                    \n",
    "            print(\"\\t\"+ \"number of matches from 6FT:\", len(seqdb))\n",
    "\n",
    "            input  = open('to_6ft_2.fasta', 'r') #list of peptides, has to be in a list\n",
    "            pep = []\n",
    "            for line in input:\n",
    "                    pep = pep + line.strip().split(\"\\t\")\n",
    "\n",
    "            print(\"\\t\"+ \"locating and matching peptides to 6FT\")\n",
    "\n",
    "            matched, unmatched = find_matches(pep, seqdb, '6FT')\n",
    "\n",
    "            if len(matched) == 0:\n",
    "                print(\"\\t\"+ \"no peptides matched to 6ft\")\n",
    "            else:\n",
    "                print(\"\\t\"+ \"writing \" + str(len(matched)) + \" peptide matches to 6FT\")\n",
    "                with open('matches_to_6ft.csv','w') as f:\n",
    "                    w = csv.writer(f)\n",
    "                    w.writerow([\"Peptide\", \"Sequence_loc\"]) #header names\n",
    "                    for key in matched:\n",
    "                        sequence = matched[key]\n",
    "                        w.writerow([key, sequence])\n",
    "\n",
    "            print(\"\\t\"+ \"writing \" + str(len(unmatched)) + \" unmatched peptides\")\n",
    "            create_files(unmatched, 'no_match_6ft')\n",
    "\n",
    "    else:\n",
    "        print(\"no peptides to search in 6FT\")\n",
    "    \n",
    "\n",
    "    #searching for proteosome catalyzed peptide spliced \n",
    "    \n",
    "    print(str(len(unmatched)) + \" peptides being searched for proteosome catalyzed peptide spliced variants\")\n",
    "\n",
    "    PCPS(\"no_match_6ft_2.fasta\")\n",
    "    \n",
    "    \n",
    "    #saving output files\n",
    "    SAAV_out = pd.read_table('categorized_blast_out_SAAV', sep = \"\\t\")\n",
    "    Sixframe_out = pd.read_csv('matches_to_6ft.csv')\n",
    "    Sixframe_notmatched = pd.read_table('no_match_6ft_2.fasta', sep = \"\\t\", names = [\"Peptides\"])\n",
    "    cis_PCPS = pd.read_table(\"cis_PCPS\", names= [\"Peptide\", \"Spliced_peptide\", \"Protein_origin\"])\n",
    "    #writing data to excel file\n",
    "    if (len(mismatched) == 0 & len(matched) == 0 & len(unmatched) == 0):\n",
    "        print(\"No significant peptides found\")\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        #creates output directory\n",
    "        try:\n",
    "            os.makedirs(output_file_path)\n",
    "            os.chdir(output_file_path)\n",
    "            print(\"Search directory created at \" + os.getcwd())\n",
    "        except OSError as error:\n",
    "            os.chdir(output_file_path)\n",
    "            print(\"Directory already exists at \" + os.getcwd())\n",
    "            \n",
    "        print(\"Creating excel file with results\")\n",
    "        with pd.ExcelWriter(file_name + '_immuno_search_out.xlsx', engine='openpyxl') as writer:\n",
    "            # Write each DataFrame to a different sheet\n",
    "            if (len(mismatched) != 0):\n",
    "                SAAV_out.to_excel(writer, sheet_name='Single_AA_variants', index=False)\n",
    "            if (len(matched) != 0):\n",
    "                Sixframe_out.to_excel(writer, sheet_name='Matches_to_six_frame', index=False)\n",
    "            if (len(unmatched) != 0):\n",
    "                Sixframe_notmatched.to_excel(writer, sheet_name='Six_frame_non_matched', index=False)\n",
    "            if (len(cis_PCPS) != 0):\n",
    "                cis_PCPS.to_excel(writer, sheet_name= \"cis_PCPS\", index= False)\n",
    "\n",
    "        os.chdir(work_dir)\n",
    "        print(\"returning back to work directory at\", work_dir)\n",
    "        return print(\"search and classification done, file saved at \", output_file_path + file_name + '_immuno_search_out.xlsx')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAAV_out = pd.read_table('categorized_blast_out_SAAV', sep = \"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>blastp_category</th>\n",
       "      <th>blastp_match</th>\n",
       "      <th>identity</th>\n",
       "      <th>peplen</th>\n",
       "      <th>sub_pos</th>\n",
       "      <th>Nterm-seq(3aa)</th>\n",
       "      <th>aligned_seq</th>\n",
       "      <th>Cterm-seq(3aa)</th>\n",
       "      <th>alignlen</th>\n",
       "      <th>mismatch</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DADYALKL</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSLPPATL</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LPEPALTL</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LPPGSLLL</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSDPDVVFS</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LYGGQAQL</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TPWLGLLV</td>\n",
       "      <td>novelpep (no match to known protein found)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Query                             blastp_category  blastp_match  \\\n",
       "0   DADYALKL  novelpep (no match to known protein found)           NaN   \n",
       "1   DSLPPATL  novelpep (no match to known protein found)           NaN   \n",
       "2   LPEPALTL  novelpep (no match to known protein found)           NaN   \n",
       "3   LPPGSLLL  novelpep (no match to known protein found)           NaN   \n",
       "4  LSDPDVVFS  novelpep (no match to known protein found)           NaN   \n",
       "5   LYGGQAQL  novelpep (no match to known protein found)           NaN   \n",
       "6   TPWLGLLV  novelpep (no match to known protein found)           NaN   \n",
       "\n",
       "   identity  peplen  sub_pos  Nterm-seq(3aa)  aligned_seq  Cterm-seq(3aa)  \\\n",
       "0       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "1       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "2       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "3       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "4       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "5       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "6       NaN     NaN      NaN             NaN          NaN             NaN   \n",
       "\n",
       "   alignlen  mismatch  gap  \n",
       "0       NaN       NaN  NaN  \n",
       "1       NaN       NaN  NaN  \n",
       "2       NaN       NaN  NaN  \n",
       "3       NaN       NaN  NaN  \n",
       "4       NaN       NaN  NaN  \n",
       "5       NaN       NaN  NaN  \n",
       "6       NaN       NaN  NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAAV_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving output files\n",
    "SAAV_out = pd.read_table('categorized_blast_out_SAAV', sep = \"\\t\")\n",
    "Sixframe_out = pd.read_csv('matches_to_6ft.csv')\n",
    "Sixframe_notmatched = pd.read_table('no_match_6ft_2.fasta', sep = \"\\t\", names = [\"Peptides\"])\n",
    "\n",
    "with pd.ExcelWriter(file_name + '_immuno_search_out.xlsx', engine='openpyxl') as writer:\n",
    "    SAAV_out.to_excel(writer, sheet_name='Single_AA_variants', index=False)\n",
    "    Sixframe_out.to_excel(writer, sheet_name='Matches_to_six_frame', index=False)\n",
    "    Sixframe_notmatched.to_excel(writer, sheet_name='Six_frame_non_matched', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading into work directory at /Users/rishyashrung/Proteomics/Immunosearch/test/\n",
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "79 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "78 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "7 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "69 peptides being searched in the six frame translated human genome\n",
      "[INFO]\u001b[0m 69 patterns loaded from file\n",
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 98\n",
      "\tlocating and matching peptides to 6FT\n",
      "\twriting 11 peptide matches to 6FT\n",
      "\twriting 58 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "58 peptides being searched for proteosome catalyzed peptide spliced variants\n",
      "\tseparate files cis_PCPS and trans_PCPS created for spliced peptides\n",
      "Directory already exists at /Users/rishyashrung/Proteomics/Immunosearch/test/1130_MHCI_1\n",
      "Creating excel file with results\n",
      "returning back to work directory at /Users/rishyashrung/Proteomics/Immunosearch/test/\n",
      "search and classification done, file saved at  /Users/rishyashrung/Proteomics/Immunosearch/test/1130_MHCI_1/1130_MHCI_1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "#test run\n",
    "\n",
    "input_file_path = \"/Users/rishyashrung/Downloads/Docs/im folder/1130_MHCI_1/1130_MHCI_1.xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = [3]\n",
    "file_name = '1130_MHCI_1'\n",
    "output_file_path = \"/Users/rishyashrung/Proteomics/Immunosearch/test/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "work_dir = \"/Users/rishyashrung/Proteomics/Immunosearch/test/\"\n",
    "\n",
    "immuno_search(work_dir, input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "145 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "135 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "7 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "128 peptides being searched in the six frame translated human genome\n",
      "\twriting 6FT results to dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 128 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnumber of matches from 6FT: 280\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 4 peptide matches to 6FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 124 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1148_E\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1148_E/1148_E_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1148_E/1148_E.xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = [0,1]\n",
    "file_name = '1148_E'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "412 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "394 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "27 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "26 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 366 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmatching peptides to 6FT\n",
      "\twriting 32 peptide matches to 6FT\n",
      "\twriting 334 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1148_MHCI\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1148_MHCI/1148_MHCI_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1148_MHCI/1148_MHCI.xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = [0,1,2,3,4]\n",
    "file_name = '1148_MHCI'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "116 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "108 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "11 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "97 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 97 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 97 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1148_MHCII\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1148_MHCII/1148_MHCII_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1148_MHCII/1148_MHCII.xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = [1]\n",
    "file_name = '1148_MHCII'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "165 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "155 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "6 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "149 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 149 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnumber of matches from 6FT: 42\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 7 peptide matches to 6FT\n",
      "\twriting 142 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1150_E\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1150_E/1150_E_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1150_E/1150_E.xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = [0,1]\n",
    "file_name = '1150_E'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '1148_MHCI/1150_MHCI/1150_MHCI.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1150_MHCI\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/Period_6/out/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m file_name  \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m    \u001b[38;5;66;03m# full file path, has to have \"/\" at the end\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mimmuno_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMHC_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgibbs_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 4\u001b[0m, in \u001b[0;36mimmuno_search\u001b[0;34m(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimmuno_search\u001b[39m(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name):   \u001b[38;5;66;03m#path of files of peptides and gibbs classification, MHC_class as an integer, Gibbs clusters to select as an array, output_file_path with / at the end\u001b[39;00m\n\u001b[1;32m      2\u001b[0m     \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# peptide length 8-11, removing gibbs junk and DB matched\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(all_data, file_name)\n\u001b[1;32m      6\u001b[0m     gibbs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(all_data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgibbs_clustering\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Bio-stats/lib/python3.12/site-packages/pandas/io/excel/_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1557\u001b[0m         )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Bio-stats/lib/python3.12/site-packages/pandas/io/excel/_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[0;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1404\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[1;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Bio-stats/lib/python3.12/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '1148_MHCI/1150_MHCI/1150_MHCI.xlsx'"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1150_MHCI/1150_MHCI.xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = []\n",
    "file_name = '1150_MHCI'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "88 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "81 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "9 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "72 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 72 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 72 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1150_MHCII\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1150_MHCII/1150_MHCII_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1150_MHCII/1150_MHCII.xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = [0]\n",
    "file_name = '1150_MHCII'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "196 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "191 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "11 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "180 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 180 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 390\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 10 peptide matches to 6FT\n",
      "\twriting 170 unmatched peptides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1153_E\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1153_E/1153_E_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1153_E/1153_E.xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = [1,2,3,4]\n",
    "file_name = '1153_E'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "59 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "55 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "6 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "49 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 49 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 49 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1153_MHCII\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1153_MHCII/1153_MHCII_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "input_file_path = \"1148_MHCI/1153_MHCII/1153_MHCII.xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = [1]\n",
    "file_name = '1153_MHCII'\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "21 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "21 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "1 peptide being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "20 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 20 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmatching peptides to 6FT\n",
      "\twriting 1 peptide matches to 6FT\n",
      "\twriting 19 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1130_E1\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1130_E1/1130_E1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1130_E1'\n",
    "input_file_path = \"im folder/1130_E1/\" + file_name + \".xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = [0,2,3]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "13 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "13 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "1 peptide being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "12 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 12 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 25\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 3 peptide matches to 6FT\n",
      "\twriting 9 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1130_E2\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1130_E2/1130_E2_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1130_E2'\n",
    "input_file_path = \"im folder/1130_E2/\" + file_name + \".xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = [0,1,3]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "734 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "733 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "50 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "678 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 678 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 676\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 49 peptide matches to 6FT\n",
      "\twriting 629 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1130_MHCI_1\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1130_MHCI_1/1130_MHCI_1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1130_MHCI_1'\n",
    "input_file_path = \"im folder/1130_MHCI_1/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "746 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "742 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "54 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "684 peptides being searched in the six frame translated human genome\n",
      "\twriting 6FT results to dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 684 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnumber of matches from 6FT: 791\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 44 peptide matches to 6FT\n",
      "\twriting 640 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1130_MHCI_2\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1130_MHCI_2/1130_MHCI_2_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1130_MHCI_2'\n",
    "input_file_path = \"im folder/1130_MHCI_2/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "9 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "9 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "1 peptide being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "8 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 8 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 8 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1130_MHCII_1\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1130_MHCII_1/1130_MHCII_1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1130_MHCII_1'\n",
    "input_file_path = \"im folder/1130_MHCII_A2/\" + file_name + \".xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = [0,1]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "14 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "14 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "3 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "11 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 11 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 11 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1130_MHCII_2\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1130_MHCII_2/1130_MHCII_2_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1130_MHCII_2'\n",
    "input_file_path = \"im folder/1130_MHCII_B2/\" + file_name + \".xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = [1,2]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "267 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "256 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "15 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "241 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 241 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 24\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 5 peptide matches to 6FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 236 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1134_E\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1134_E/1134_E_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1134_E'\n",
    "input_file_path = \"im folder/1134_E/\" + file_name + \".xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = [0,1,2,3]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "366 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "357 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "25 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "332 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 332 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 771\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 43 peptide matches to 6FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 289 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1134_MHCI\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1134_MHCI/1134_MHCI_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1134_MHCI'\n",
    "input_file_path = \"im folder/1134_MHCI/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "145 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "132 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "6 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "126 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 126 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 126 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1134_MHCII\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1134_MHCII/1134_MHCII_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1134_MHCII'\n",
    "input_file_path = \"im folder/1134_MHCII/\" + file_name + \".xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "100 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "98 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "2 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "96 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 96 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 60\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 9 peptide matches to 6FT\n",
      "\twriting 87 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1136_E\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1136_E/1136_E_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1136_E'\n",
    "input_file_path = \"im folder/1136_E/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = [0,1,2]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "191 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "183 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "10 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "173 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 173 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 46\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 7 peptide matches to 6FT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 166 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1136_MHCI\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1136_MHCI/1136_MHCI_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1136_MHCI'\n",
    "input_file_path = \"im folder/1136_MHCI/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = [0,1,2,4]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "110 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "100 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "3 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "97 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 97 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 97 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search directory created at D:\\Period_6\\out\\1136_MHCII\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1136_MHCII/1136_MHCII_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1136_MHCII'\n",
    "input_file_path = \"im folder/1136_MHCII/\" + file_name + \".xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "118 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "117 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "8 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "107 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 107 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tnumber of matches from 6FT: 326\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 18 peptide matches to 6FT\n",
      "\twriting 89 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1137_E1\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1137_E1/1137_E1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1137_E1'\n",
    "input_file_path = \"im folder/1137_E1/\" + file_name + \".xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 8 and 15 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "126 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "125 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "14 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "110 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 110 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 488\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 18 peptide matches to 6FT\n",
      "\twriting 92 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Directory already exists at D:\\Period_6\\out\\1137_E2\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1137_E2/1137_E2_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1137_E2'\n",
    "input_file_path = \"im folder/1137_E2/\" + file_name + \".xlsx\"\n",
    "MHC_class = 'E'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "99 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tknown HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "98 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "8 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "90 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 90 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 152\n",
      "\tmatching peptides to 6FT\n",
      "\twriting 14 peptide matches to 6FT\n",
      "\twriting 76 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search directory created at D:\\Period_6\\out\\1137_MHCI_1\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1137_MHCI_1/1137_MHCI_1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1137_MHCI_1'\n",
    "input_file_path = \"im folder/1137_MHCI_1/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selected gibbs clusters based on input\n",
      "selecting peptides with length between 8 and 11 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "88 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "88 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "6 peptides being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "82 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 82 patterns loaded from file"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmatching peptides to 6FT\n",
      "\twriting 11 peptide matches to 6FT\n",
      "\twriting 71 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1137_MHCI_2\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1137_MHCI_2/1137_MHCI_2_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1137_MHCI_2'\n",
    "input_file_path = \"im folder/1137_MHCI_2/\" + file_name + \".xlsx\"\n",
    "MHC_class = '1'\n",
    "gibbs_cluster = [1,2,3]\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "4 peptides being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "4 peptides being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "\tfiles SAAV , SAAV_2 created\n",
      "1 peptide being searched for Single Amino Acid Variants\n",
      "\treading output\n",
      "\tall is gud for blast_out_SAAV\n",
      "3 peptides being searched in the six frame translated human genome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO]\u001b[0m 3 patterns loaded from file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\twriting 6FT results to dictionary\n",
      "\tnumber of matches from 6FT: 0\n",
      "\tmatching peptides to 6FT\n",
      "\tno peptides matched to 6ft\n",
      "\twriting 3 unmatched peptides\n",
      "\tfiles no_match_6ft , no_match_6ft_2 created\n",
      "Search directory created at D:\\Period_6\\out\\1137_MHCII_1\n",
      "Creating excel file with results\n",
      "search and classification done, file saved at  D:/Period_6/out/1137_MHCII_1/1137_MHCII_1_immuno_search_out.xlsx\n"
     ]
    }
   ],
   "source": [
    "file_name = '1137_MHCII_1'\n",
    "input_file_path = \"im folder/1137_MHCII_C2/\" + file_name + \".xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering peptides found by DB search\n",
      "Selecting all gibbs clusters\n",
      "selecting peptides with length between 12 and 17 AA\n",
      "generating lists and files for further analysis\n",
      "\tfiles peptides , peptides_2 created\n",
      "1 peptide being searched for known HLAs\n",
      "\treading output\n",
      "\tall is gud for HLA_blast_out\n",
      "\tgenerating lists and files for further analysis\n",
      "\tno known HLA found\n",
      "\tfiles to_blastp , to_blastp_2 created\n",
      "1 peptide being searched for human canonical proteins\n",
      "\treading output\n",
      "\tall is gud for blastp_out_human_canonical\n",
      "\tfiles to_6ft , to_6ft_2 created\n",
      "\tgenerating lists and files for further analysis\n",
      "no potential SAAVs, proceeding to 6FT search\n",
      "1 peptide being searched in the six frame translated human genome\n",
      "no match to 6FT\n",
      "No significant peptides found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The process cannot access the file because it is being used by another process.\n"
     ]
    }
   ],
   "source": [
    "file_name = '1137_MHCII_2'\n",
    "input_file_path = \"im folder/1137_MHCII_D2/\" + file_name + \".xlsx\"\n",
    "MHC_class = '2'\n",
    "gibbs_cluster = []\n",
    "output_file_path = \"D:/Period_6/out/\" + file_name  + \"/\"    # full file path, has to have \"/\" at the end\n",
    "\n",
    "\n",
    "immuno_search(input_file_path, MHC_class, gibbs_cluster, output_file_path, file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cb2030-labs-environment-windows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
