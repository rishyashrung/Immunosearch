{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from Bio import SeqIO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(peptide, db):\n",
    "    search = {}\n",
    "    for string in peptide:\n",
    "        search[string] = []\n",
    "        for key, value in db.items():\n",
    "            if string in value:\n",
    "                    search[string].append((key))\n",
    "    \n",
    "    unmatched = []\n",
    "    #fn for filtering the 6FT matched dictionary\n",
    "    def my_filtering_function(pair):\n",
    "        key, value = pair\n",
    "        if value == []:\n",
    "            return False  # filter pair out of the dictionary\n",
    "        else:\n",
    "            return True  # keep pair in the filtered dictionary\n",
    "        \n",
    "    matched = dict(filter(my_filtering_function, search.items()))\n",
    "\n",
    "    for key, value in search.items():\n",
    "        if (value == []):\n",
    "            unmatched.append(key)\n",
    "    if (len(matched) + len(unmatched) == len(search)):  #to make sure the dictionary filter works fine\n",
    "        return matched\n",
    "    else:\n",
    "        return print(\"\\t\" + \"error in separating matches\")\n",
    "    \n",
    "\n",
    "def split_string(s):\n",
    "    splits_dict = {}\n",
    "    # Ensure the string is long enough to be split into two parts each with at least `min_length` characters\n",
    "    if len(s) < 6:\n",
    "        return splits_dict\n",
    "    \n",
    "    for i in range(3, len(s) - 2):\n",
    "        part1 = s[:i]\n",
    "        part2 = s[i:]\n",
    "        if len(part2) >= 3:\n",
    "            splits_dict[part1] = part2\n",
    "    return splits_dict\n",
    "\n",
    "def PCPS(input_file):\n",
    "        \n",
    "        input1= SeqIO.parse('db/human_canonical.fasta',\"fasta\") \n",
    "        seqdb={}\n",
    "        for record in input1:\n",
    "                seq=str(record.seq)\n",
    "                if record.id not in seqdb:\n",
    "                        seqdb[record.id]=seq\n",
    "\n",
    "        input = open(input_file, \"r\")\n",
    "        output = open('cis_PCPS_out', \"w\")\n",
    "        output_2 = open('trans_PCPS_out', \"w\")\n",
    "        for line in input:\n",
    "                row=line.strip().split(\"\\t\")\n",
    "                pep = row[0]\n",
    "                split_combinations = split_string(pep)\n",
    "                part1_list = list(split_combinations.keys())\n",
    "                part2_list = list(split_combinations.values())\n",
    "                match_1 = find_matches(part1_list, seqdb)\n",
    "                match_2 = find_matches(part2_list, seqdb)\n",
    "                row = []\n",
    "                for key,value in match_1.items():\n",
    "                        for pro_1 in match_1[key]:\n",
    "                                if (split_combinations[key] in match_2.keys()):\n",
    "                                        for pro_2 in match_2[split_combinations[key]]:\n",
    "                                                if pro_1 == pro_2:\n",
    "                                                    result = (f\"{key}|{split_combinations[key]}\" + \"\\t\" + f\"{pro_2}\")\n",
    "                                                    output.write(str(pep) + \"\\t\" + result + \"\\n\")\n",
    "                                                else:\n",
    "                                                    result_2 = (f\"{key}|{split_combinations[key]}\" + \"\\t\" + f\"{pro_1}:{pro_2}\")\n",
    "                                                    output_2.write(str(pep) + \"\\t\" + result_2 + \"\\n\")\n",
    "        input.close()\n",
    "        output.close()\n",
    "        output_2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fn that gets matches and position of matches from peptide_list to fasta\n",
    "\n",
    "def get_pos(substring, string):\n",
    "# Find the starting position\n",
    "    start_position = string.find(substring)\n",
    "\n",
    "    if start_position != -1:\n",
    "        # Calculate the ending position\n",
    "        end_position = start_position + len(substring) - 1\n",
    "        return(start_position, end_position)\n",
    "    \n",
    "\n",
    "def find_matches(peptide, db):\n",
    "    search_6ft = {}\n",
    "    pos_6ft = {}\n",
    "    for string in peptide:\n",
    "        search_6ft[string] = []\n",
    "        pos_6ft[string] = []\n",
    "        for key, value in db.items():\n",
    "            if string in value:\n",
    "                    search_6ft[string].append((key))\n",
    "                    pos_6ft[string].append(get_pos(string,value))\n",
    "                        \n",
    "    unmatched = []\n",
    "    #fn for filtering the 6FT matched dictionary\n",
    "    def my_filtering_function(pair):\n",
    "        key, value = pair\n",
    "        if value == []:\n",
    "            return False  # filter pair out of the dictionary\n",
    "        else:\n",
    "            return True  # keep pair in the filtered dictionary\n",
    "        \n",
    "    matched = dict(filter(my_filtering_function, search_6ft.items()))\n",
    "    positions = dict(filter(my_filtering_function, pos_6ft.items()))\n",
    "\n",
    "    for key, value in search_6ft.items():\n",
    "        if (value == []):\n",
    "            unmatched.append(key)\n",
    "    if (len(matched) + len(unmatched) == len(search_6ft)):  #to make sure the dictionary filter works fine\n",
    "        return (matched, unmatched, positions)\n",
    "    else:\n",
    "        return print(\"\\t\" + \"error in separating matches\")\n",
    "    \n",
    "\n",
    "def split_string(s):\n",
    "    splits_dict = {}\n",
    "    # Ensure the string is long enough to be split into two parts each with at least `min_length` characters\n",
    "    if len(s) < 6:\n",
    "        return splits_dict\n",
    "    \n",
    "    for i in range(3, len(s) - 2):\n",
    "        part1 = s[:i]\n",
    "        part2 = s[i:]\n",
    "        if len(part2) >= 3:\n",
    "            splits_dict[part1] = part2\n",
    "    return splits_dict\n",
    "\n",
    "def PCPS(input_file):\n",
    "        \n",
    "        input1= SeqIO.parse('db/human_canonical.fasta',\"fasta\") \n",
    "        seqdb={}\n",
    "        for record in input1:\n",
    "                seq=str(record.seq)\n",
    "                if record.id not in seqdb:\n",
    "                        seqdb[record.id]=seq\n",
    "\n",
    "        input = open(input_file, \"r\")\n",
    "        output = open('cis_PCPS_out', \"w\")\n",
    "        output_2 = open('trans_PCPS_out', \"w\")\n",
    "        for line in input:\n",
    "                row=line.strip().split(\"\\t\")\n",
    "                pep = row[0]\n",
    "                split_combinations = split_string(pep)\n",
    "                part1_list = list(split_combinations.keys())\n",
    "                part2_list = list(split_combinations.values())\n",
    "                match_1, unmatch_1, pos_1 = find_matches(part1_list, seqdb)\n",
    "                match_2, unmatch_2, pos_2 = find_matches(part2_list, seqdb)\n",
    "                row = []\n",
    "                for key,value in match_1.items():\n",
    "                        for pro_1 in match_1[key]:\n",
    "                                if (split_combinations[key] in match_2.keys()):\n",
    "                                        for pro_2 in match_2[split_combinations[key]]:\n",
    "                                                if pro_1 == pro_2:\n",
    "                                                    result = (f\"{key}|{split_combinations[key]}\" + \"\\t\" + f\"{pro_2}\")\n",
    "                                                    output.write(str(pep) + \"\\t\" + result + \"\\n\")\n",
    "                                                else:\n",
    "                                                    result_2 = (f\"{key}|{split_combinations[key]}\" + \"\\t\" + f\"{pro_1}:{pro_2}\")\n",
    "                                                    output_2.write(str(pep) + \"\\t\" + result_2 + \"\\n\")\n",
    "        input.close()\n",
    "        output.close()\n",
    "        output_2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rishyashrung/Proteomics/Immunosearch/test'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'test'\n",
      "/Users/rishyashrung/Proteomics/Immunosearch/test\n"
     ]
    }
   ],
   "source": [
    "cd test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCPS(\"no_match_6ft_2.fasta\")\n",
    "# PCPS = pd.read_table(\"trans_PCPS_out\", names= [\"Peptide\", \"PCPS_match\"])\n",
    "# spliced_peps = pd.unique (PCPS[\"Peptide\"])\n",
    "# from_6ft = pd.read_table(\"no_match_6ft_2.fasta\", names = [\"Peptides\"])\n",
    "# remaining = from_6ft[~from_6ft[\"Peptides\"].isin(spliced_peps)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bio-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
